{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and set the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x10fd37580> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10fd36940> model_name='gpt-4o' openai_api_key=SecretStr('**********') openai_proxy=''\n",
      "content='Generative AI refers to a class of artificial intelligence systems designed to generate new content, such as text, images, music, or other data, that mimics the style and characteristics of the input data it was trained on. Unlike traditional AI systems that focus on recognizing patterns or making decisions based on existing data, generative AI creates new data that can be indistinguishable from human-created content.\\n\\nKey technologies in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: These consist of two neural networks, a generator and a discriminator, that are trained together. The generator creates new data, while the discriminator evaluates it against real data. The two networks improve iteratively until the generated data is highly realistic.\\n\\n2. **Variational Autoencoders (VAEs)**: These are a type of neural network designed to encode input data into a compressed latent space and then decode it back to the original space, with the added capability of generating new data by sampling from the latent space.\\n\\n3. **Transformers**: These models, particularly in the context of natural language processing (NLP), are designed to handle sequential data and have been used to create highly sophisticated text generators like GPT (Generative Pre-trained Transformer) series. They use self-attention mechanisms to understand the context and generate coherent and contextually relevant text.\\n\\nApplications of generative AI are vast and include:\\n\\n- **Text Generation**: Creating articles, stories, or even entire books.\\n- **Image Generation**: Producing realistic images or artworks.\\n- **Music Composition**: Generating new musical pieces.\\n- **Data Augmentation**: Creating synthetic data to augment training datasets for machine learning models.\\n- **Style Transfer**: Applying the style of one image to the content of another, commonly used in art and photography.\\n\\nGenerative AI has transformative potential across various industries, including entertainment, design, healthcare, and more, but it also raises ethical and practical concerns, such as the potential for creating deepfakes or generating misleading information.' response_metadata={'token_usage': {'completion_tokens': 409, 'prompt_tokens': 13, 'total_tokens': 422}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None} id='run-021a1a5a-c2d4-4e34-bd79-a73f4280ebcb-0' usage_metadata={'input_tokens': 13, 'output_tokens': 409, 'total_tokens': 422}\n"
     ]
    }
   ],
   "source": [
    "llm =ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)\n",
    "\n",
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert AI Engineer. Provide me answers based on the questions')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a LLM chain\n",
    "\n",
    "- Prompt and LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Certainly! Langsmith is a tool designed to enhance the development, evaluation, and monitoring of applications that use Large Language Models (LLMs). It offers a suite of features that streamline the creation and optimization of these applications, making it easier to build robust and efficient systems.\\n\\nHere are some key functionalities of Langsmith:\\n\\n1. **Logging and Tracing**: Langsmith allows you to log and trace the execution of LLM applications. This helps in understanding how the application is performing and where potential bottlenecks or errors may be occurring.\\n\\n2. **Dataset Management**: The tool provides support for creating and managing datasets, which are crucial for training and evaluating LLMs. This includes functionalities for uploading, organizing, and versioning datasets.\\n\\n3. **Evaluation**: Langsmith offers tools for evaluating the performance of LLMs against specific metrics. This is essential for ensuring that the models are meeting the required standards and are improving over time.\\n\\n4. **Experiment Tracking**: It enables the tracking of different experiments, including the configurations, parameters, and results. This helps in comparing different approaches and identifying the most effective strategies.\\n\\n5. **Monitoring**: Langsmith includes monitoring capabilities to keep an eye on the performance of LLM applications in production. This ensures that any issues can be quickly identified and addressed.\\n\\n6. **Integration**: The tool is designed to integrate seamlessly with other components and platforms commonly used in the development of LLM applications, such as cloud services, machine learning frameworks, and data storage solutions.\\n\\nOverall, Langsmith aims to provide a comprehensive environment for the lifecycle management of LLM applications, from initial development through to deployment and ongoing maintenance.' response_metadata={'token_usage': {'completion_tokens': 335, 'prompt_tokens': 33, 'total_tokens': 368}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_bc2a86f5f5', 'finish_reason': 'stop', 'logprobs': None} id='run-d2e53b51-d0c0-4aec-a48e-87b9c7dd2d7d-0' usage_metadata={'input_tokens': 33, 'output_tokens': 335, 'total_tokens': 368}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain = prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a output parser\n",
    "- Adding the output parser to LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! As of my last update in 2023, \"Langsmith\" doesn't refer to a widely recognized or specific concept, product, or entity in the fields of AI, technology, or engineering. It might be a newly coined term, a niche product, or a specialized tool that has emerged after my last training data.\n",
      "\n",
      "However, if \"Langsmith\" is a term you encountered in a specific context, such as a new software tool, a company, a framework, or even a novel concept in AI or programming, providing additional context would help me give a more accurate and detailed answer. \n",
      "\n",
      "Please let me know if there are more details or if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
